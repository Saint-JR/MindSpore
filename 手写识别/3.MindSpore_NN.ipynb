{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 全连接神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [2. 2. 2.]]\n",
      "[[3. 3. 3. 3. 3.]\n",
      " [6. 6. 6. 6. 6.]]\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "import numpy as np\n",
    "from mindspore import Tensor\n",
    "\n",
    "# 构造输入张量\n",
    "# 两个样本，每个样本有3个输入\n",
    "input = Tensor(np.array([[1, 1, 1], [2, 2, 2]]), mindspore.float32)\n",
    "print(input)\n",
    "\n",
    "# 构造全连接网络，输入通道为3，输出通道为5\n",
    "net = nn.Dense(in_channels=3, out_channels=5, weight_init=1)\n",
    "output = net(input)\n",
    "print(output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 1080, 960)\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Tensor\n",
    "\n",
    "# mindspore.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, pad_mode='same', padding=0, dilation=1, \n",
    "#                     group=1, has_bias=False, weight_init='normal', bias_init='zeros', data_format='NCHW')\n",
    "\n",
    "# 图片数，通道数，图像高，图像宽\n",
    "input = Tensor(np.ones([1, 3, 1080, 960]), mindspore.float32) \n",
    "\n",
    "# 输入通道数为3，输出通道数为24， 卷积核大小为5， 步长为1，padding方式same，有偏置项，权重初始化为normal\n",
    "net = nn.Conv2d(in_channels=3, out_channels=24, kernel_size=5, stride=1, pad_mode='same', has_bias=True, weight_init='normal')\n",
    "\n",
    "# 图片数，通道数，图像高，图像宽\n",
    "output = net(input).shape\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 2. 0. 2. 0.]\n"
     ]
    }
   ],
   "source": [
    "input_x = Tensor(np.array([-1, 2, -3, 2, -1]), mindspore.float16)\n",
    "\n",
    "relu = nn.ReLU()\n",
    "output = relu(input_x)\n",
    "print(output)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[5 1 3 6]\n",
      "   [1 7 0 9]\n",
      "   [4 8 9 2]\n",
      "   [8 8 4 8]]\n",
      "\n",
      "  [[7 1 8 5]\n",
      "   [7 8 3 4]\n",
      "   [7 2 9 4]\n",
      "   [6 5 8 4]]]]\n",
      "-----------------------------------\n",
      "[[[[7. 9.]\n",
      "   [8. 9.]]\n",
      "\n",
      "  [[8. 8.]\n",
      "   [7. 9.]]]]\n"
     ]
    }
   ],
   "source": [
    "input_x = np.random.randint(0, 10, [1, 2, 4, 4])\n",
    "print(input_x)\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "# 最大池化，池化大小2x2， 步长为2\n",
    "pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "output = pool(Tensor(input_x, mindspore.float32))  \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1.]\n",
      "  [2. 2.]]\n",
      "\n",
      " [[3. 3.]\n",
      "  [4. 4.]]]\n",
      "-----------------------------------\n",
      "[[1. 1. 2. 2.]\n",
      " [3. 3. 4. 4.]]\n"
     ]
    }
   ],
   "source": [
    "from mindspore import Tensor\n",
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "\n",
    "input = Tensor(np.array([[[1, 1], [2, 2]], [[3, 3], [4, 4]]]), mindspore.float32)\n",
    "print(input)\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "net = nn.Flatten()\n",
    "output = net(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搭建LeNet-5网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## LeNet5网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn # 各类网络层都在nn里面\n",
    "from mindspore.common.initializer import Normal # 参数初始化\n",
    "\n",
    "class LeNet5(nn.Cell):\n",
    "    \n",
    "    # 定义算子\n",
    "    def __init__(self, num_class=10, num_channel=1):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # 卷积层\n",
    "        self.conv1 = nn.Conv2d(num_channel, 6, 5, pad_mode='valid')\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, pad_mode='valid')\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc1 = nn.Dense(4 * 4 * 16, 120, weight_init=Normal(0.02))\n",
    "        self.fc2 = nn.Dense(120, 84, weight_init=Normal(0.02))\n",
    "        self.fc3 = nn.Dense(84, num_class, weight_init=Normal(0.02))\n",
    "        \n",
    "        # 激活函数\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # 最大池化成\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # 网络展开\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "    # 建构网络\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "# 定义神经网络\n",
    "lenet = LeNet5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True,reduction=\"mean\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "net_opt = nn.Momentum(lenet.trainable_params(), lr, momentum) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## 模型编译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import Model # 承载网络结构\n",
    "from mindspore.nn.metrics import Accuracy # 测试模型用\n",
    "\n",
    "# 模型编译\n",
    "model = Model(lenet, net_loss, net_opt, metrics={'accuracy': Accuracy()}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## 模型训练\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - #### 实验数据下载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://zhuanyejianshe.obs.cn-north-4.myhuaweicloud.com/chuangxinshijianke/cv-nlp/MNIST.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - #### 引入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAckAAACOCAYAAABaFfMRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAD+0lEQVR4nO3d3XErRRCGYfsUURAFSVBEQJREQJEEURAGOjdcyXpdPmK1MzvzPLeukn+25a96u3f0frvd3gCAj76N/gEAYFZCEgCCkASAICQBIAhJAAhCEgDCT5998ddvv3s+ZGN//fvH+4jvq+72NqLu1NzePqs5nSQABCEJAEFIAkAQkgAQhCQABCEJAEFIAkAQkgAQPj1MAIA9/fnP34e8zm8//3LI64yikwSAICQBIAhJAAhCEgCCxR2AzR21pLMinSQABCEJAEFIAkAwkwTYiPnjj9FJAkAQkgAQhCQABCEJAGGLxZ1nB9VXP70e4MxFnRX/Z+okASAISQAIQhIAwpIzyaPuwb/yXv6K9+53d4WHtNXd2s6uwR3qSScJAEFIAkAQkgAQhCQAhCUXd67gfsC+wwB8JVdY0nlE3fGsXWtFJwkAQUgCQBCSABCEJACEJRd37gfMV12yYB6vqqFnlyFeearUrgsas3Oazhg6SQAIQhIAgpAEgLDkTPLeo3vr5pSUo2rjlTOdr7y2Gr+2M6+f+WPTSQJAEJIAEIQkAAQhCQBhi8WdR0Y/xM0cjryeqyw/OGBgba7lj9FJAkAQkgAQhCQAhG1nkvB/mOtwpFfuOpxZq8/Os7/y+496z+kkASAISQAIQhIAgpAEgGBx5xOrDNNZj0MteGTGT4c56vuNWu7RSQJAEJIAEIQkAAQzyf+YPzIzn1K/jrMP1d9pfv2Kw/l1kgAQhCQABCEJAEFIAkC43OLOFYfQZw/qeb2jFgSuWM/MQ/28nk4SAIKQBIAgJAEgCEkACFMv7hhKf3T/N7HIM48r1qv64UhH1tMs7yedJAAEIQkAQUgCQJh6JslHZkjHevT3nGUWAmcZ/X9l5vecThIAgpAEgCAkASAISQAIUy/uWKpghDPrTo1ztrOXdK5ezzpJAAhCEgCCkASAMPVM8pH7++ln3+8e/dAtY6xy3Vf5PXje1WeEZ9NJAkAQkgAQhCQABCEJAOFyiztnDp0tOXBl6pfVnVHjOkkACEISAIKQBIAw9UzS/BG+Tg1fg0PtnzOqvnWSABCEJAAEIQkAQUgCQJh6cQdWZ2GDt7evLaXMWCs7LIvpJAEgCEkACEISAIKQBICw7eLODgNn1qV+9+Oaj6GTBIAgJAEgCEkACNvOJGGEGR8IB5pOEgCCkASAICQBIAhJAAhbLO54CJcRjlzSUcMwhk4SAIKQBIAgJAEgTD2TNIdhR+oe5qGTBIAgJAEgCEkACEISAMLUiztwZRZw4Pp0kgAQhCQABCEJAEFIAkAQkgAQhCQABCEJAEFIAkB4v91uo38GAJiSThIAgpAEgCAkASAISQAIQhIAgpAEgPAdN0TMjWnTf48AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import mindspore.dataset as ds   # 数据集的载入\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_dir = \"./MNIST/train\"  # 数据集路径\n",
    "\n",
    "# 从mnist dataset读取3张图片\n",
    "mnist_dataset = ds.MnistDataset(dataset_dir=dataset_dir, num_samples=3)\n",
    "\n",
    "# 设置图像大小\n",
    "plt.figure(figsize=(8,8))\n",
    "i = 1\n",
    "\n",
    "# 打印3张子图\n",
    "for dic in mnist_dataset.create_dict_iterator(output_numpy=True):\n",
    "    plt.subplot(3,3,i)\n",
    "    plt.imshow(dic['image'][:,:,0])\n",
    "    plt.axis('off')\n",
    "    i +=1\n",
    "plt.show() \n",
    "\n",
    "import mindspore.dataset.transforms.c_transforms as C # 常用转化算子\n",
    "import mindspore.dataset.vision.c_transforms as CV # 图像转化算子\n",
    "from mindspore.common import dtype as mstype # 数据形态转换\n",
    "from mindspore.common.initializer import Normal # 参数初始化\n",
    "\n",
    "def create_dataset(data_path, batch_size=32):\n",
    "    \"\"\" \n",
    "    数据预处理与批量输出的函数\n",
    "    \n",
    "    Args:\n",
    "        data_path: 数据路径\n",
    "        batch_size: 批量大小\n",
    "    \"\"\"\n",
    "    \n",
    "    # 加载数据集\n",
    "    data = ds.MnistDataset(data_path)\n",
    "    \n",
    "    # 打乱数据集\n",
    "    data = data.shuffle(buffer_size=10000)\n",
    "    \n",
    "    # 数据标准化参数\n",
    "    # MNIST数据集的 mean = 33.3285，std = 78.5655\n",
    "    mean, std = 33.3285, 78.5655 \n",
    "\n",
    "    # 定义算子\n",
    "    nml_op = lambda x : np.float32((x-mean)/std) # 数据标准化，image = (image-mean)/std\n",
    "    hwc2chw_op = CV.HWC2CHW() # 通道前移（为配适网络，CHW的格式可最佳发挥昇腾芯片算力）\n",
    "    type_cast_op = C.TypeCast(mstype.int32) # 原始数据的标签是unint，计算损失需要int\n",
    "\n",
    "    # 算子运算\n",
    "    data = data.map(operations=type_cast_op, input_columns='label')\n",
    "    data = data.map(operations=nml_op, input_columns='image')\n",
    "    data = data.map(operations=hwc2chw_op, input_columns='image')\n",
    "\n",
    "    # 批处理\n",
    "    data = data.batch(batch_size)\n",
    "    \n",
    "    # 重复\n",
    "    data = data.repeat(1)\n",
    "\n",
    "    return data\n",
    "\n",
    "train_path = os.path.join('MNIST','train') # 训练集路径\n",
    "train_data = create_dataset(train_path) # 定义训练数据集\n",
    "\n",
    "test_path = os.path.join('MNIST','test') # 测试集路径\n",
    "test_data = create_dataset(test_path) # 定义测试数据集 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - #### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(27532:25144,MainProcess):2022-11-27-15:07:49.754.843 [mindspore\\train\\model.py:500] The CPU cannot support dataset sink mode currently.So the training process will be performed with dataset not sink.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1875, loss is 0.038763184\n",
      "epoch: 2 step: 1875, loss is 0.17519149\n",
      "epoch: 3 step: 1875, loss is 0.21999122\n"
     ]
    }
   ],
   "source": [
    "#设定loss监控\n",
    "from mindspore.train.callback import LossMonitor\n",
    "loss_cb = LossMonitor(per_print_times=train_data.get_dataset_size())\n",
    "# 训练模型\n",
    "model.train(3, train_data, loss_cb) # 训练3个epoch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(27532:25144,MainProcess):2022-11-27-15:08:25.524.974 [mindspore\\train\\model.py:893] CPU cannot support dataset sink mode currently.So the evaluating process will be performed with dataset non-sink mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.981}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 评估模型\n",
    "model.eval(test_data) # 测试网络"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('MindSpore1.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b481270e4f32a5330818c7d06dca840dd59c8779142471ce787048eca7ccd567"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
